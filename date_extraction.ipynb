{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pedro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import pytesseract\n",
    "import pdfplumber\n",
    "from pdf2image import convert_from_path\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from unidecode import unidecode\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "class DocumentExtractor():\n",
    "    def __init__(self, path):\n",
    "        self.dir_path = path\n",
    "\n",
    "    def similar(self, a, b):\n",
    "        return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "    def get_text_from_pdf(self):\n",
    "        pages = convert_from_path(self.path, 300, fmt='jpeg')\n",
    "        extracted_text = []\n",
    "        for img in pages:\n",
    "            img = np.array(img)\n",
    "            img = cv2.resize(img, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            kernel = np.ones((2, 2), np.uint8)\n",
    "            img = cv2.dilate(img, kernel, iterations=1)\n",
    "            img = cv2.erode(img, kernel, iterations=1)\n",
    "            img = cv2.adaptiveThreshold(cv2.bilateralFilter(img, 9, 75, 75), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "            img = Image.fromarray(img)\n",
    "            text = pytesseract.image_to_string(img, lang='por')\n",
    "            extracted_text.append(text)\n",
    "        return (extracted_text)\n",
    "\n",
    "    def read_file(self):\n",
    "        pdf = pdfplumber.open(self.path)\n",
    "        text = []\n",
    "        for page in pdf.pages:\n",
    "            text.append(page.extract_text())\n",
    "        if None in text:\n",
    "            print(\"Handling file as image...\")\n",
    "            text = self.get_text_from_pdf()\n",
    "        text = ' (NEWPAGE) '.join(text)\n",
    "        return text\n",
    "\n",
    "    def clean_text(self, text, remove_stop_words=True):\n",
    "        stop_words = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "        text_by_words = text.replace('\\n', ' ').split(' ')\n",
    "        if remove_stop_words:\n",
    "            formated_text = [unidecode(word.lower()) for word in text_by_words if (len(word) >= 1) & (word.lower() not in stop_words)]\n",
    "        else:\n",
    "            formated_text = [unidecode(word.lower()) for word in text_by_words if (len(word) >= 1)]\n",
    "        return formated_text\n",
    "\n",
    "    def get_prazo_clauses(self, text):\n",
    "        sentences = []\n",
    "        for idx, i in enumerate(text):\n",
    "            if self.similar('clausula', i) > 0.7:\n",
    "                clause = text[idx:]\n",
    "                if any(test in clause[:10] for test in ['prazo', 'vigencia']):\n",
    "                    for j in range(1, len(clause)):\n",
    "                        if self.similar('clausula', clause[j]) > 0.7:\n",
    "                            clause = clause[:j]\n",
    "                            break\n",
    "                    # print(' '.join(clause))\n",
    "                    sentences.append(' '.join(clause))\n",
    "        return sentences\n",
    "\n",
    "    def read_all_documents(self):\n",
    "        prazos = []\n",
    "        if os.path.isdir(self.dir_path):\n",
    "            for file in sorted(os.listdir(self.dir_path)):\n",
    "                print('Reading File {}'.format(file))\n",
    "                self.path = '{}/{}'.format(self.dir_path, file)\n",
    "                text = self.read_file()\n",
    "                print('Cleaning Texts')\n",
    "                text = self.clean_text(text, remove_stop_words=False)\n",
    "                print('Getting Prazos')\n",
    "                sentences = self.get_prazo_clauses(text)\n",
    "                prazos.append(sentences)\n",
    "                print('\\n')\n",
    "        else:\n",
    "            print('Reading File {}'.format(self.dir_path))\n",
    "            self.path = self.dir_path\n",
    "            text = self.read_file()\n",
    "            print('Cleaning Texts')\n",
    "            text = self.clean_text(text, remove_stop_words=False)\n",
    "            print('Getting Prazos')\n",
    "            sentences = self.get_prazo_clauses(text)\n",
    "            prazos.append(sentences)\n",
    "            print('\\n')\n",
    "        return prazos\n",
    "\n",
    "    def write_prazos(self, prazos):\n",
    "        erros = []\n",
    "        with open('output.txt', 'w') as f:\n",
    "            for i in range(len(prazos)):\n",
    "                f.write('FILE: {}\\n'.format(i))\n",
    "                if len(prazos) == 0:\n",
    "                    erros.append(i)\n",
    "                    f.write('NONE FOUND! \\n')\n",
    "                for _string in prazos[i]:\n",
    "                    f.write(str(_string) + '\\n')\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading File ./documents/contratante/09.pdf\n",
      "Handling file as image...\n",
      "Cleaning Texts\n",
      "Getting Prazos\n",
      "\n",
      "\n",
      "[['ciainsula sexia: dos prazos de exboicao o prazo para prestacao dos servicos ora contratado sera de 60 (sessenta) dias a contar da data de recebimento da ordem de execucao de servicos, podendo ser prorrogado a criterio da administracao. f']]\n"
     ]
    }
   ],
   "source": [
    "mypath = './documents/contratante/09.pdf'\n",
    "extractor = DocumentExtractor(mypath)\n",
    "file = extractor.read_all_documents()\n",
    "print(file)\n",
    "# extractor.write_prazos(prazos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import display # to display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.16.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pkg_resources\n",
    "pkg_resources.working_set.by_key['pdf2image'].version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
